{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "583850fa",
   "metadata": {},
   "source": [
    "# Traffic Congestion Analysis with ANN\n",
    "This notebook performs traffic congestion analysis and trains an Artificial Neural Network (ANN) to predict congestion levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d824574f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d83f8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/kaggle/input/worldwide-traffic-congestion-ranking/TrafficIndex_19Jun2022-26Jun2022.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "# Select numeric features for ANN\n",
    "features = ['AverageTCI', 'WorstTCI', 'BestTCI', 'TCIDiff']\n",
    "df = df[features].dropna()\n",
    "\n",
    "# Define input (X) and output (y)\n",
    "X = df.drop('AverageTCI', axis=1)\n",
    "y = df['AverageTCI']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50252f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define ANN model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))  # Regression output\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9b5d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"RÂ² Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f10297",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot loss\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
